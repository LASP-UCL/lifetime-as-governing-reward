import gymnasium as gym
import torch
import numpy as np
from minigrid.wrappers import FullyObsWrapper
from customenvs import *
import time
import argparse
from utils import get_state_tensor
from distutils.util import strtobool

import imageio
from PIL import Image, ImageDraw, ImageFont

import sys
sys.path.append('../')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

parser = argparse.ArgumentParser()
parser.add_argument("--env-id", type=str, default="SimpleBoxes")
parser.add_argument("--fully-obs", type=lambda x: bool(strtobool(x)), default=False, nargs="?", const=True)
parser.add_argument("--max-timesteps", type=int, default=256)
parser.add_argument("--capture-gif", default=False, action='store_true')
parser.add_argument("--agent-name", default="test")
parser.add_argument("--seed", type=int, default=1)
args = parser.parse_args()

env_id = args.env_id
render_mode = "rgb_array" if args.capture_gif else "human"

if "Energy" in env_id:

    energy_args = {"render_mode": render_mode,
                    "agent_start_dir": "random",
                    "agent_start_pos": (1,1),
                    "time_bonus": 0.1,
                    "box_open_reward": 0,
                    "seed": args.seed}
    if env_id == "EnergyBoxes":
        env = EnergyBoxesEnv(**energy_args)
    elif env_id == "EnergyBoxesHard":
        env = EnergyBoxesHardEnv(**energy_args)
    elif env_id == "EnergyBoxesDelay":
        env = EnergyBoxesDelayEnv(**energy_args)

else:
    env = gym.make(env_id, render_mode=render_mode)
if args.fully_obs:
    env = FullyObsWrapper(env)

AGENT_MODEL_NAME = f"trained-models/{env_id}/actor_{args.agent_name}.pth"
#agent = torch.load(AGENT_MODEL_NAME)
max_timesteps = args.max_timesteps

# Array to store frames for gif
frames = []

# Generate trajectories
state = env.reset()[0]
total_return, episode_return, episode_number, episode_timestep = 0, 0, 0, 0

def add_text_to_image(img, timestep, episode_timestep, episode, episode_reward, energy=None):

    img_pil = Image.fromarray(img)
    width, height = img_pil.size
    img_pil.resize((width*2, height*2))
    width, height = img_pil.size

    draw = ImageDraw.Draw(img_pil)

    if "Energy" in env_id:
        draw.text((5, 5/height), 'Step: {}'.format(episode_timestep+1))
        draw.text((0.5 * width, 5/height), 'Energy: {}'.format(energy+1))
        draw.text((0.15 * width, 0.9 * height), 'Episode Reward: {:.1f}'.format(episode_reward))
    else:
        draw.text((5, 5/height), 'Time Step: {}'.format(timestep+1))
        draw.text((0.6 * width, 5/height), 'Episode: {}'.format(episode+1))
        draw.text((0.15 * width, 0.9 * height), 'Episode Reward: {:.1f}'.format(episode_reward))

    return np.array(img_pil)

for t in range(max_timesteps):

    kwargs = {}
    episode_timestep += 1

    if "Energy" in env_id:
        current_energy = env.energy-1
        kwargs["energy"] = current_energy
    
    state['image'] = state['image'].reshape(1, *state['image'].shape)
    state['direction'] = np.array([state['direction']])
    obs = get_state_tensor(state)
    #action = agent.get_action_and_value(obs)[0].item()
    action = env.action_space.sample() #random behaviour
    state, reward, terminated, truncated, info = env.step(action) 
    total_return += reward
    episode_return += reward

    if args.capture_gif:
        img = env.render()
        img = add_text_to_image(img, timestep=t, 
                                    episode_timestep=episode_timestep,
                                    episode=episode_number, 
                                    episode_reward=episode_return,
                                    **kwargs)
        frames.append(img)

    if terminated or truncated: 
        state = env.reset()[0]
        print(f"Episode return: {episode_return:.2f}")
        episode_return = 0
        episode_number += 1
        episode_timestep = 0

if args.capture_gif:
    imageio.mimsave(f'trajectory-{args.agent_name}.gif', frames, duration=0.4)

env.close()
